<!DOCTYPE html>
<html>

<head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#">
<meta charset="utf-8" />
<meta http-equiv='X-UA-Compatible' content='IE=edge'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>
<title>Khoa học dữ liệu</title>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> 
<link href="https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300" rel="stylesheet">
<!-- <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet"> -->
<link href="https://fonts.googleapis.com/css?family=Roboto|Source+Sans+Pro" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Fira+Sans" rel="stylesheet">
<link rel="icon" type="image/jpg" href="assets/images/logo.jpg" sizes="32x32">
<link rel="canonical" href="https://phamdinhkhanh.github.io"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="author" content="Phạm Đình Khánh" />
<meta property="og:title" content="" />
<meta property="og:site_name" content="Khanh's blog" />
<meta property="og:url" content="https://phamdinhkhanh.github.io" />
<meta property="og:description" content="" />

<meta property="og:type" content="article" />
<meta property="article:published_time" content="" />


<meta property="article:author" content="Khanh" />
<meta property="article:section" content="" />
   


<link rel="alternate" type="application/atom+xml" title="Khanh's blog - Atom feed" href="/feed.xml" />

<style>
	
</style>
<!-- -- Import latext  -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
	skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
	inlineMath: [['$','$']]
  }
});
</script>

<!-- Google Analytics -->

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-89509207-1', 'auto');
// ga('send', 'pageview');
ga('send', 'pageview', {
'page': '/',
'title': ''
});
</script>


<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-KTCD8BX');</script>
<!-- End Google Tag Manager -->
</head>
<style>
	
</style>

<body>
	<div id="fb-root"></div>
	<!-- <script>(function(d, s, id) { -->
	  <!-- var js, fjs = d.getElementsByTagName(s)[0]; -->
	  <!-- if (d.getElementById(id)) return; -->
	  <!-- js = d.createElement(s); js.id = id; -->
	  <!-- js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.9"; -->
	  <!-- fjs.parentNode.insertBefore(js, fjs); -->
	<!-- }(document, 'script', 'facebook-jssdk'));</script> -->
	<br>
	<div content = "container">
		<div class="row">
			<div class="col-md-2 hidden-xs hidden-sm">
				<a  href="/">
					<img width="100%" style="padding-bottom: 3mm;" src="/assets/images/img.jpg" /> </a>
				<br>
				<nav>
					<div class="header">Latest</div>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/05/11/Hypothesis_Statistic.html">Apenddix 1 - Lý thuyết phân phối và kiểm định thống kê</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/04/29/ModelWord2Vec.html">Mô hình Word2Vec</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/04/29/ModelWord2Vec.ipynb">Modelword2vec</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/04/22/L%C3%BD_thuy%E1%BA%BFt_v%E1%BB%81_m%E1%BA%A1ng_LSTM.html">Lý thuyết về mạng LSTM part 2</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/01/07/k-thu-t-feature-engineering.html">Kĩ thuật feature engineering</a></li>
					
				</nav>
			</div>
			<div class="col-md-8 col-xs-12" style="z-index:1">
				<nav class="navbar navbar-inverse" style="background-color: #046897">
					<div class = "container-fluid">
						<div class = "navbar-header>
							<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
								<span class="icon-bar"></span>
								<span class="icon-bar"></span>
								<span class="icon-bar"></span>
							</button>
							<a class="navbar-brand" href="/">
								<span style="color:#FFF">Khoa học dữ liệu - Khanh's blog</span>
							</a>
						</div>
						<br>
						<br>
						<div class="collapse navbar-collapse navbar-right" id="myNavbar">
							<ul class="nav navbar-nav">
								<li><a href="/home"><span style="color: #fff"> Home</span></a></li>
								<li><a href="/about"><span style="color: #fff"> About</span></a></li>
								<!-- <li><a href="/da"><span style="color: #fff">Data Analytics</span></a></li> -->
								<!-- <li><a href="/cv"><span style="color: #fff">Computer Vision</span></a></li> -->
								<!-- <li><a href="/nlp"><span style="color: #fff">NLP</span></a></li> -->
								<!-- <li><a href="/code"><span style="color: #fff">Code</span></a></li> -->
								<li><a href="/book"><span style="color: #fff">Book</span></a></li>
							</ul>
						</div>
					</div>
				</nav>
				<div class="PageNavigation">
				</div>
				<h1 itemprop="name" class="post-title"></h1>
				<div>
					<div>
<ul>
  
	  <div>
		<hr />
		<h2><a class="post-link" style="text-align: left; color: #204081; font-weight: bold" href="/2019/05/11/Hypothesis_Statistic.html">Apenddix 1 - Lý thuyết phân phối và kiểm định thống kê</a></h2>
		<br />
		<p>
		<h1 id="phần-1---thống-kê">Phần 1 - Thống kê</h1>


		</p>
		<a href="/2019/05/11/Hypothesis_Statistic.html" sylte="color: #204081;">Xem tiếp » </a> 
		<span class="post-date" style="float: right; "><strong>11 May 2019</strong></span>
	  </div>
	
  
	  <div>
		<hr />
		<h2><a class="post-link" style="text-align: left; color: #204081; font-weight: bold" href="/2019/04/29/ModelWord2Vec.html">Mô hình Word2Vec</a></h2>
		<br />
		<p>
		<h1 id="1-giới-thiệu-word-representation">1. Giới thiệu Word Representation.</h1>
<p>Khác với các mô hình xử lý ảnh khi các giá trị đầu vào là cường độ màu sắc đã được mã hoá thành giá trị số trong khoảng [0, 255]. Mô hình xử lý ngôn ngữ tự nhiên có đầu vào chỉ là các chữ cái kết hợp với dấu câu. Làm sao chúng ta có thể lượng hoá được những từ ngữ để làm đầu vào cho mạng nơ ron? Kĩ thuật one-hot véc tơ sẽ được áp dụng để thực hiện điều này. Trước khi đi vào phương pháp biểu diễn, chúng ta cần làm rõ một số khái niệm:</p>


		</p>
		<a href="/2019/04/29/ModelWord2Vec.html" sylte="color: #204081;">Xem tiếp » </a> 
		<span class="post-date" style="float: right; "><strong>29 Apr 2019</strong></span>
	  </div>
	
  
	  <div>
		<hr />
		<h2><a class="post-link" style="text-align: left; color: #204081; font-weight: bold" href="/2019/04/29/ModelWord2Vec.ipynb">Modelword2vec</a></h2>
		<br />
		<p>
		{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Giới thiệu biểu diễn từ\n",
    "\n",
    "### 1.1. Word Representation\n",
    "Khác với các mô hình xử lý ảnh khi các giá trị đầu vào là cường độ màu sắc đã được mã hoá thành giá trị số trong khoảng [0, 255]. Mô hình xử lý ngôn ngữ tự nhiên có đầu vào chỉ là các chữ cái kết hợp với dấu câu. Làm sao chúng ta có thể lượng hoá được những từ ngữ để làm đầu vào cho mạng nơ ron? Kĩ thuật one-hot véc tơ sẽ được áp dụng để thực hiện điều này. Trước khi đi vào phương pháp biểu diễn, chúng ta cần làm rõ một số khái niệm:\n",
    "\n",
    "* Documents (Văn bản): Là tợp hợp các câu trong cùng một đoạn văn có mối liên hệ với nhau. Văn bản có thể được coi như một bài báo, bài văn,....\n",
    "* Corpus (Bộ văn bản): Là một tợp hợp gồm nhiều văn bản thuộc các đề tài khác nhau, tạo thành một nguồn tài nguyên dạng văn bản. Một văn bản cũng có thể được coi là corpus của các câu trong văn bản. Các bộ văn bảnCác lớn thường có từ vài nghìn đến vài trăm nghìn văn bản trong nó. Một số bộ văn bản trong tiếng việt có thể được download từ nguồn wikipedia, [VNCoreNLP](https://github.com/vncorenlp/VnCoreNLP).\n",
    "* Character (kí tự): Là tợp hợp gồm các chữ cái (nguyên âm và phụ âm) và dấu câu. Mỗi một ngôn ngữ sẽ có một bộ các kí tự khác nhau.\n",
    "* Word (từ vựng): Là các kết hợp của các kí tự tạo thành những từ biểu thị một nội dung, định nghĩa xác định, chẳng hạn `con người` có thể coi là một từ vựng. Từ vựng có thể bao gồm từ đơn có 1 âm tiết và từ ghép nhiều hơn 1 âm tiết. Khác với tiếng anh khi các từ chủ yếu là từ đơn. Tiếng việt có rất nhiều những từ ghép 2, 3 âm tiết. Do đó chúng ta cần phải có từ điển để thực hiện tách từ (tokenize) trong câu. Một số package thông dụng trong Tiếng Việt có sẵn chức năng tách từ được sử dụng phổ biến là [underthesea](https://github.com/undertheseanlp/underthesea ), [pyvi](https://pypi.org/project/pyvi/), [VNCoreNLP](https://github.com/vncorenlp/VnCoreNLP), [RDRsegmenter](https://github.com/datquocnguyen/RDRsegmenter), [coccoc-tokenizer](https://github.com/coccoc/coccoc-tokenizer). Kết quả tokenize có thể khác nhau tuỳ thuộc vào cách định nghĩa từ ghép ở mỗi package. Khi xử lý ngôn ngữ tự nhiên cho một số lĩnh vực đặc biệt cần phải có từ điển chuyên ngành, vì vậy cần phải customize riêng biệt.\n",
    "* Dictionary (từ điển): Là tợp hợp các từ vựng xuất hiện trong văn bản.\n",
    "* Volcabulary (từ vựng): Tợp hợp các từ được trích xuất trong văn bản. Tương tự như từ điển.\n",
    "\n",
    "Trước khi biểu diễn từ chúng ta cần xác định từ điển của corpus. Các từ là hữu hạn và được lặp lại trong quá trình biểu diễn các văn bản trong corpus. Do đó thông qua từ điển gồm tợp hợp tất cả các từ có thể xuất hiện ta sẽ mã hoá được các câu dưới dạng ma trận mà mỗi dòng của nó là một véc tớ one-hot của từ. \n",
    "\n",
    "**Định nghĩa One-hot véc tơ của từ:**\n",
    "Giả sử chúng ta có từ điển là tợp hợp gồm $n$ từ vựng `{anh, em, gia đình, bạn bè,...}`. Khi đó mỗi từ sẽ được đại diện bởi một giá trị chính là index của nó. Từ `anh` có index = 0, `gia đình` có index = 2. One-hot véc tơ của từ vựng thứ $i$, $i \\leq (n-1)$ sẽ là véc tơ $\\mathbf{e}_i = [0, ..., 0, 1, 0, ..., 0] \\in \\mathbb{R}^{n}$ sao cho các phần tử $e_{ij}$ của véc tơ thoả mãn:\n",
    "\n",
    "$$\n",
    "  \\begin{equation}\n",
    "  \\begin{cases}\n",
    "    e_{ij} = 0, &amp; \\text{if}\\space i \\neq j\\\\\n",
    "    e_{ii} = 1\n",
    "  \\end{cases}\n",
    "  \\end{equation}\n",
    "$$\n",
    "\n",
    "$ \\forall i, j \\in \\mathbb{N}; 0 \\leq i,j  \\leq n-1 $\n",
    "\n",
    "**Hàm biểu diễn One-hot véc tơ:**\n",
    "\n",
    "Trong python chúng ta có thể biến đổi các từ sang dạng one-hot véc tơ thông qua hàm OneHotEncoder của sklearn. Nhưng trước tiên ta sẽ gán index cho các class bằng LabelEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class of words:  ['anh' 'bạn bè' 'em' 'gia đình']\n",
      "Convert to number:  [0 2 3 1 0 2]\n",
      "Invert into classes:  ['anh' 'em' 'gia đình' 'bạn bè' 'anh' 'em']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "words = ['anh', 'em', 'gia đình', 'bạn bè', 'anh', 'em']\n",
    "le.fit(words)\n",
    "\n",
    "print('Class of words: ', le.classes_)\n",
    "# Biến đổi sang dạng số\n",
    "x = le.transform(words)\n",
    "print('Convert to number: ', x)\n",
    "# Biến đổi lại sang class\n",
    "print('Invert into classes: ', le.inverse_transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thực hiện OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes_indices:  [('anh', 0), ('bạn bè', 1), ('em', 2), ('gia đình', 3)]\n",
      "One-hot categories and indices: [array(['anh', 'bạn bè', 'em', 'gia đình'], dtype=object), array([0, 1, 2, 3], dtype=object)]\n",
      "Words and corresponding indices:  [('anh', 0), ('em', 2), ('gia đình', 3), ('bạn bè', 1), ('anh', 0), ('em', 2)]\n",
      "Transform words into one-hot matrices: \n",
      " [[1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0.]]\n",
      "Inverse transform to categories from one-hot matrices: \n",
      " [['anh' 0]\n",
      " ['em' 2]\n",
      " ['gia đình' 3]\n",
      " ['bạn bè' 1]\n",
      " ['anh' 0]\n",
      " ['em' 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "oh = OneHotEncoder()\n",
    "classes_indices = list(zip(le.classes_, np.arange(len(le.classes_))))\n",
    "print('Classes_indices: ', classes_indices)\n",
    "oh.fit(classes_indices)\n",
    "print('One-hot categories and indices:', oh.categories_)\n",
    "# Biến đổi list words sang dạng one-hot\n",
    "words_indices = list(zip(words, x))\n",
    "print('Words and corresponding indices: ', words_indices)\n",
    "one_hot = oh.transform(words_indices).toarray()\n",
    "print('Transform words into one-hot matrices: \\n', one_hot)\n",
    "print('Inverse transform to categories from one-hot matrices: \\n', oh.inverse_transform(one_hot))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Word Embedding\n",
    "Sau khi biểu diễn từ dưới dạng one-hot véc tơ, mô hình đã có thể học được từ dữ liệu số. Tuy nhiên dữ liệu này chưa đáp ứng được một số tính chất đó là:\n",
    "\n",
    "1. Mối quan hệ tương quan giữa cặp 2 từ khác biệt bất kì luôn là không tương quan (tức bằng 0). Do đó khoảng cách cosine_similarity giữa các từ cùng nhóm và các từ khác là không có sự khác biệt. Trong khi để phân tích được ngữ nghĩa của từ chúng ta cần các véc tơ có khoảng cách của chúng là gần nhau khi từ thuộc cùng 1 nhóm.\n",
    "2. Kích thước của véc tơ sẽ phụ thuộc vào số lượng từ vựng có trong bộ văn bản dẫn đến chi phí tính toán rất lớn khi tập dữ liệu lớn.\n",
    "3. Khi bổ sung thêm các từ vựng mới số chiều của véc tơ có thể thay đổi theo dẫn đến sự không ổn định trong shape.\n",
    "\n",
    "Chính vì thế chúng ta cần phải thực hiện phép nhúng từ bằng các thuật toán nhúng từ (word embedding) sang các véc tơ sao cho:\n",
    "\n",
    "1. Mỗi từ được biểu diễn bởi một véc tơ có số chiều xác định trước.\n",
    "2. Các từ thuộc cùng 1 nhóm thì có khoảng cách gần nhau trong không gian.\n",
    "\n",
    "Xoay quanh các phương pháp nhúng từ chúng ta có rất nhiều cách khác nhau. Nhưng chúng ta có thể có các thuật toán chính sau:\n",
    "\n",
    "* Word2Vec: Về bản chất đây chính là một phép auto encoder nhằm giảm chiều dữ liệu của ma trận đồng xuất hiện của các cặp từ input và output. Trong đó input là từ hiện tại và output là các từ liền kề xung quanh nó. Chẳng hạn chúng ta có 2 câu văn như sau:\n",
    "\n",
    "`Khoa học dữ liệu là một lĩnh vực đòi hỏi kiến thức về toán và lập trình. Tôi rất yêu thích khoa học dữ liệu.`\n",
    "\n",
    "Tập từ điển sẽ bao gồm các từ sau:\n",
    "\n",
    "`[khoa học, dữ liệu, là, một, lĩnh vực, đòi hỏi, kiến thức, về, toán, và, lập trình, tôi, rất, yêu, thích]`\n",
    "\n",
    "Khi đó biểu diễn các từ trong ma trận đồng xuất hiện như bên dưới:\n",
    "\n",
    "&lt;img src = \"attachment:image.png\" width=\"600px\" height=\"600px\"&gt;&lt;/img&gt;\n",
    "\n",
    "\n",
    "&gt; **Hình 1:** Ma trận đồng xuất hiện\n",
    "\n",
    "**Phương pháp SVD:**\n",
    "\n",
    "[SVD](https://www.kaggle.com/phamdinhkhanh/singular-value-decomposition) là một phương pháp giảm chiều dữ liệu hiệu quả dựa trên phép phân tích suy biến. Chúng ta cũng có thể tìm ra biểu diễn của mỗi từ trong từ điển bằng một véc tơ các nhân tố ẩn dựa vào việc lựa chọn một số lượng các giá trị đặc trưng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization of sentences:  ['Khoa học', 'dữ liệu', 'là', 'một', 'lĩnh vực', 'đòi hỏi', 'kiến thức', 'về', 'toán', 'và', 'lập trình', '.', 'Tôi', 'rất', 'yêu thích', 'Khoa học', 'dữ liệu', '.']\n"
     ]
    }
   ],
   "source": [
    "import scipy.linalg as ln \n",
    "import numpy as np\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "sentence = 'Khoa học dữ liệu là một lĩnh vực đòi hỏi kiến thức về toán và lập trình. Tôi rất yêu thích Khoa học dữ liệu.'\n",
    "token = word_tokenize(sentence)\n",
    "# Tokenize câu search\n",
    "print('tokenization of sentences: ', token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "# Tạo ma trận coherence dưới dạng sparse thông qua khai báo vị trí khác 0 của trục x và y\n",
    "row = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13]\n",
    "col = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14]\n",
    "data =      [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "X = coo_matrix((data, (row, col)), shape=(15, 15)).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of U:  (15, 15)\n",
      "Length of diagonal:  15\n",
      "Shape of V:  (15, 15)\n"
     ]
    }
   ],
   "source": [
    "# Thực hiện phân tích suy biến:\n",
    "U, S_diag, V = ln.svd(X)\n",
    "print('Shape of U: ', U.shape)\n",
    "print('Length of diagonal: ', len(S_diag))\n",
    "print('Shape of V: ', V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các ma trận $\\mathbf{U, V}$ lần lượt là ma trận trực giao suy biến trái và phải. Ma trận $\\mathbf{S}$ là ma trận đường chéo chính. Ta có:\n",
    "$$\\mathbf{U_{15*15}S_{15*15}V_{15*15} = X}$$\n",
    "Đường chéo chính của ma trận $\\mathbf{S_{15*15}}$ được sắp xếp theo thứ tự giảm dần. Cần lựa chọn bao nhiêu chiều dữ liệu để biểu diễn từ sẽ lấy bấy nhiêu dòng của ma trận đường chéo chính. Để véc tơ biểu diễn sát nhất chúng ta nên lấy các dòng tương ứng với các giá trị đặc trưng lớp nhất. Chẳng hạn muốn biểu diễn các từ dưới dạng véc tơ 6 chiều ta lấy tích $\\mathbf{S_{6*15}V_{15*15}} = \\mathbf{X_{6*15}}$. Khi đó các cột của ma trận đầu ra $\\mathbf{X_{6*15}}$ sẽ là một véc tơ nhúng của từ tại vị trí tương ứng trong từ điển."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S truncate: \n",
      " [[2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Word Embedding 6 dimensionality: \n",
      " [[0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "S_truncate = np.zeros(shape = (6, 15))\n",
    "np.fill_diagonal(S_truncate, S_diag[:6])\n",
    "print('S truncate: \\n', S_truncate)\n",
    "print('Word Embedding 6 dimensionality: \\n', np.dot(S_truncate, V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phương pháp auto encoder**\n",
    "\n",
    "Auto encoder được xây dựng trên một mạng nơ ron có 3 layer: input, hidden layer và output. Trong đó số units ở input và output là bằng nhau. Số units ở hidden layer sẽ qui định số chiều của véc tơ biểu diễn từ và thông thường sẽ nhỏ hơn số units ở đầu vào.\n",
    "\n",
    "![Auto Encoder](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1522830223/AutoEncoder_kfqad1.png)\n",
    "\n",
    "&gt; **Hình 2:** phương pháp auto encoder với số units ở đầu vào bằng đầu ra.\n",
    "\n",
    "Bên dưới chúng ta sẽ tiến hành nhúng từ thông qua auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_59 (Dense)             (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 6)                 96        \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 15)                105       \n",
      "=================================================================\n",
      "Total params: 441\n",
      "Trainable params: 441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 2.5121 - acc: 0.0667\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.5057 - acc: 0.0667\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.4984 - acc: 0.1333\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 723us/step - loss: 2.4944 - acc: 0.2000\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 989us/step - loss: 2.4883 - acc: 0.2000\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.4837 - acc: 0.2000\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.4771 - acc: 0.2000\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.4715 - acc: 0.2000\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.4664 - acc: 0.2000\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.4599 - acc: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "&lt;keras.callbacks.History at 0x1a33fb7128&gt;"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "def autoencoder(input_unit, hidden_unit):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_unit, input_shape = (15,), activation = 'relu'))\n",
    "    model.add(Dense(hidden_unit, activation = 'relu'))\n",
    "    model.add(Dense(input_unit, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = Adam(),\n",
    "                 metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "autoencoder = autoencoder(input_unit = 15, hidden_unit = 6)\n",
    "\n",
    "autoencoder.fit(X, X, epochs = 10, batch_size = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các hệ số kết nối hidden units với một unit ở output sẽ là véc tơ nhúng biểu diễn từ thông qua các nhân tố ẩn. Trích xuất layers cuối cùng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedding_matrix:  (6, 15)\n",
      "Embedding_matrix: \n",
      " [[ 0.11808676 -0.47047567  0.3186977   0.23248333  0.05837977  0.1292606\n",
      "   0.2350207  -0.4080731  -0.17247424  0.06323338 -0.3132843   0.2069143\n",
      "  -0.37366134 -0.13071582 -0.29980803]\n",
      " [ 0.46851903 -0.30391607  0.09523088 -0.2361995   0.317649   -0.08800185\n",
      "   0.32691342  0.48520023 -0.13241765 -0.16801077 -0.0239985  -0.15473264\n",
      "  -0.2844733  -0.12070271 -0.24092981]\n",
      " [ 0.4680032  -0.29023093 -0.49763098 -0.08051014 -0.03391296 -0.27106762\n",
      "  -0.43716308 -0.07777721 -0.04868034  0.30084372 -0.5271066  -0.06496984\n",
      "  -0.03932458  0.39960355  0.1122064 ]\n",
      " [ 0.25448513 -0.47528145  0.4002875  -0.1837667  -0.06924736 -0.02120411\n",
      "  -0.12858388 -0.5031701  -0.423671   -0.24284944 -0.06794518 -0.03816652\n",
      "  -0.4342707   0.4751678  -0.36948627]\n",
      " [-0.30760276  0.36330557  0.15232134 -0.21623856  0.46234655 -0.13568267\n",
      "  -0.4481275   0.01572114  0.33407384  0.31344682 -0.45141435  0.16516274\n",
      "  -0.22828826  0.43214297 -0.26092646]\n",
      " [-0.52130836 -0.48797372 -0.3086521  -0.37332314  0.45806032  0.11436766\n",
      "   0.37782735 -0.17935473 -0.37505084  0.44381875  0.485933    0.03528535\n",
      "  -0.05198446 -0.42145354  0.07560384]]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = model.layers[2].get_weights()[0]\n",
    "bias = model.layers[2].get_weights()[1]\n",
    "\n",
    "print('Shape of embedding_matrix: ', embedding_matrix.shape)\n",
    "print('Embedding_matrix: \\n', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21231182"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine(x, y):\n",
    "    cos_sim = np.dot(x, y)/(norm(x)*norm(y))\n",
    "    return cos_sim\n",
    "# Véc tơ biểu diễn từ khoa học\n",
    "e0 = list(embedding_matrix[:, 0])\n",
    "# Véc tơ biểu diễn từ dữ liệu\n",
    "e1 = list(embedding_matrix[:, 1])\n",
    "# Quan hệ tương quan ngữ nghĩa giữa từ khoa học và dữ liệu\n",
    "cosine(e0, e1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tìm từ tương quan nhất với một từ thông qua khoảng cách cosine_similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosines:  [1.0, 0.21231176, 0.087005645, 0.17149675, -0.37679073, -0.5198645, -0.14550264, 0.1320176, -0.18437378, -0.4929914, -0.5009279, -0.5269199, -0.32587945, 0.38836747, -0.26020408]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0, 13,  1,  3,  7,  2,  6,  8, 14, 12,  4,  9, 10,  5, 11])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Từ có khoảng cách lớn nhất với từ khoa học theo thứ tự\n",
    "cosines = [cosine(e0, embedding_matrix[:, i]) for i in np.arange(15)]\n",
    "print('cosines: ', cosines)\n",
    "np.argsort([cosine(e0, embedding_matrix[:, i]) for i in np.arange(15)])[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "như vậy 2 từ ở vị trí thứ 13 và 1 tương ứng với `yêu` và `dữ liệu` là 2 từ có mối liên hệ gần nhất với từ `khoa học`. Xét với bối cảnh của 2 câu văn trên cho thấy khá phù hợp bởi 2 cụm từ: `yêu khoa_học` và `khoa_học dữ_liệu`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 biến thể chính của word2vec:**\n",
    "Mô hình word2vec có 2 phương pháp chính là skip-grams và CBOW như sau:\n",
    "\n",
    "**skip-grams**: \n",
    "Giả sử chúng ta có một câu văn như sau: `Tôi muốn một chiếc cốc màu_xanh đựng hoa quả dầm`. Để thu được một phép nhúng từ tốt hơn chúng ta sẽ thiết lập ra các từ mục tiêu (target) và từ bối cảnh (context). Một từ mục tiêu sẽ được giải thích tốt hơn nếu được học dựa trên các từ bối cảnh. Việc xác định bối cảnh của từ sẽ dựa trên một khoảng cách xác định xung quanh nó mà chúng ta gọi là cửa sổ (window). Việc di chuyển các cửa sổ này dọc theo chiều dài của câu từ trái qua phải sẽ tạo thành các n-grams (trong trường hợp cửa sổ độ dài 2 là bi-gram và 3 là tri-gram). Từ bối cảnh và mục tiêu sẽ được lựa chọn từ một trong các vị trí ngẫu nhiên trong một gram. Chẳng hạn với việc lựa chọn từ `cốc` làm bối cảnh nếu lấy từ tiếp theo, từ liền trước, từ cách đó liền trước 2, 3 từ ta sẽ lần lượt thu được các từ mục tiêu như sau:\n",
    "\n",
    "<table> \n",
    "    <tr> <th>Bối cảnh (context)</th> <th>Mục tiêu (target)</th> </tr> \n",
    "    <tr> <td>cốc</td> <td>màu_xanh</td> </tr> \n",
    "    <tr> <td>cốc</td> <td>chiếc</td> </tr> \n",
    "    <tr> <td>cốc</td> <td>một</td> </tr> \n",
    "    <tr> <td>cốc</td> <td>muốn</td> </tr> \n",
    "</table>\n",
    "\n",
    "\n",
    "Thông qua quá trình xây dựng một thuật toán học có giám sát nhằm dự báo các từ mục tiêu dựa vào từ bối cảnh, mô hình sẽ tìm ra biểu diễn của từ bối cảnh.\n",
    "\n",
    "* Mục tiêu: $$\\text{Context-c (\"cốc\")} \\rightarrow \\text{Target-t (\"màu_xanh\")}$$\n",
    "Từ từ bối cảnh c ta muốn dự báo từ mục tiêu t\n",
    "\n",
    "* Mô hình:\n",
    "\n",
    "![skip-grams model](https://unixtitan.net/images/network-vector-design-4.png)\n",
    "\n",
    "&gt; **Hình 3**: Kiến trúc mô hình skip-grams\n",
    "\n",
    "\n",
    "Cũng giống như các quá trình biểu diễn từ thông thường khác, mô hình sẽ biểu diễn một từ bối cảnh dưới dạng one-hot véc tơ $\\mathbf{o_c}$ làm đầu vào cho một mạng nơ ron có tầng ẩn gồm 300 nhân tố ẩn. Kết quả ở output layer là một hàm softmax tính xác xuất để các từ mục tiêu phân bố vào những từ trong vocabulary (10000 từ). Dựa trên quá trình feed forward và back propagation mô hình sẽ tìm ra tham số tối ưu để kết quả dự báo từ mục tiêu là chuẩn xác nhất. Khi đó quay trở lại tầng hidden layer ta sẽ thu được đầu ra tại tầng này là ma trận nhúng $\\mathbf{E} \\in \\mathbb{R}^{n\\times 300}$. \n",
    "\n",
    "$$\\mathbf{o_c} \\rightarrow \\mathbf{E} \\rightarrow \\mathbf{e_c} \\rightarrow \\text{softmax} \\rightarrow \\mathbf{\\hat{y}}$$\n",
    "\n",
    "Khi áp dụng hàm softmax, xác xuất ở đầu ra có dạng:\n",
    "$$\\mathbf{P(t=v_{i}|c)} = \\frac{e^{\\mathbf{\\theta_{i}}^{T}\\mathbf{e_c}}}{\\sum_{j=1}^{10000}e^{\\mathbf{\\theta_{j}}^{T}\\mathbf{e_c}}}$$\n",
    "\n",
    "$\\mathbf{\\theta_{i}} \\in \\mathbb{R}^{300}$ là các véc tơ tham số thể hiện sự liên kết giữa các units ở hidden layer với output layer.\n",
    "\n",
    "Kết quả dự báo mô hình mạng nơ ron càng chuẩn xác thì véc tơ nhúng sẽ càng thể hiện được mối liên hệ trên thực tế giữa từ bối cảnh và mục tiêu chuẩn xác. Do đó nó càng lượng hoá chính xác từ. Kết quả cuối cùng ta quan tâm chính là các dòng của ma trận $\\mathbf{E}$. Chúng là các véc tơ nhúng $\\mathbf{e_c}\\in \\mathbb{R}^{300}$ đại diện cho một từ bối cảnh tương ứng với véc tơ one-hot ở input.\n",
    "\n",
    "\n",
    "**CBOW**: Chúng ta nhận thấy rằng mô hình skip-grams sẽ rất tốn chi phí để tính toán vì mẫu số xác xuất là tổng của toàn bộ số mũ cơ số tự nhiên của vocalbulary. Để hạn chế chi phí tính toán mô hình CBOW (continueos backward model) ra đời chỉ tạo ra một xác xuất duy nhất thay vì 10000 xác xuất ở đầu ra. Xuất phát từ ý tưởng đó, mô hình sẽ xây dựng kiến trúc dự báo chỉ gồm 1 đầu ra duy nhất là từ ở vị trí trung tâm được dự báo từ đầu vào là các từ bối cảnh.\n",
    "\n",
    "\n",
    "![CBOW](https://cdn-images-1.medium.com/max/800/1*UVe8b6CWYykcxbBOR6uCfg.png)\n",
    "&gt; **Hình 4**: Kiến trúc CBOW \n",
    "\n",
    "Bên dưới chúng ta cùng sử dụng mô hình word2vec theo phương pháp CBOW để nhúng các từ bối cảnh thành những véc tơ có 300 chiều bằng `keras`. Dữ liệu input là các câu trong kinh thánh được lấy từ [bible-kjv.txt](http://www.gutenberg.org/ebooks/10). Để xây dựng mô hình sẽ đi qua các bước sau đây:\n",
    "\n",
    "1. Tạo bộ từ điển cho toàn bộ các câu trong kinh thánh sao cho mỗi từ được gán giá trị bởi 1 số index.\n",
    "2. Mã hoá toàn bộ các câu văn bằng index. \n",
    "3. Xác định các cặp `Context --&gt; Target` tương ứng với input và output của mô hình. Trong đó từ `Target` là từ hiện tại ở vị trí `index`, các từ `Context` nằm ở khoảng `[index - window_size, index + window_size]`. Padding giá trị 0 tại những context không đủ độ dài là `2*window_size`.\n",
    "4. Xây dựng mạng nơ ron.\n",
    "5. Huấn luyện mô hình.\n",
    "6. Trích xuất ma trận nhúng tại đầu ra của hidden layer.\n",
    "\n",
    "Bước 1: Tạo từ điển"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/phamdinhkhanh/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/phamdinhkhanh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 12746\n",
      "Vocabulary Sample: [('the', 1), ('and', 2), ('of', 3), ('to', 4), ('that', 5), ('in', 6), ('he', 7), ('shall', 8), ('unto', 9), ('for', 10)]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from nltk.corpus import gutenberg\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt')\n",
    "norm_bible = gutenberg.sents('bible-kjv.txt') \n",
    "norm_bible = [' '.join(doc) for doc in norm_bible]\n",
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(norm_bible)\n",
    "word2id = tokenizer.word_index\n",
    "\n",
    "# build vocabulary of unique words\n",
    "word2id['PAD'] = 0\n",
    "id2word = {v:k for k, v in word2id.items()}\n",
    "vocab_size = len(word2id)\n",
    "\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Vocabulary Sample:', list(word2id.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước 2: Mã hoá toàn bộ các câu văn bằng index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding sentence by index:  [[1, 53, 1342, 6058], [1, 280, 2678, 3, 1, 53, 1342, 6058], [1, 254, 448, 3, 162, 194, 8769], [43, 43, 6, 1, 734, 27, 1368, 1, 205, 2, 1, 139], [43, 48, 2, 1, 139, 26, 258, 2085, 2, 2086, 2, 551, 26, 46, 1, 266, 3, 1, 1030]]\n"
     ]
    }
   ],
   "source": [
    "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in norm_bible]\n",
    "print('Embedding sentence by index: ', wids[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước 3: Xác định `Context --&gt; Target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context (X): ['the', 'old', 'of', 'the'] -&gt; Target (Y): testament\n",
      "Context (X): ['old', 'testament', 'the', 'king'] -&gt; Target (Y): of\n",
      "Context (X): ['testament', 'of', 'king', 'james'] -&gt; Target (Y): the\n",
      "Context (X): ['of', 'the', 'james', 'bible'] -&gt; Target (Y): king\n",
      "Context (X): ['the', 'first', 'of', 'moses'] -&gt; Target (Y): book\n",
      "Context (X): ['first', 'book', 'moses', 'called'] -&gt; Target (Y): of\n",
      "Context (X): ['book', 'of', 'called', 'genesis'] -&gt; Target (Y): moses\n",
      "Context (X): ['1', '1', 'the', 'beginning'] -&gt; Target (Y): in\n",
      "Context (X): ['1', 'in', 'beginning', 'god'] -&gt; Target (Y): the\n",
      "Context (X): ['in', 'the', 'god', 'created'] -&gt; Target (Y): beginning\n",
      "Context (X): ['the', 'beginning', 'created', 'the'] -&gt; Target (Y): god\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def generate_context_word_pairs(corpus, window_size, vocab_size):\n",
    "    context_length = window_size*2\n",
    "    for words in corpus:\n",
    "        sentence_length = len(words)\n",
    "        # print('words: ', words)\n",
    "        for index, word in enumerate(words):\n",
    "            context_words = []\n",
    "            label_word   = [] \n",
    "            # Start index of context\n",
    "            start = index - window_size\n",
    "            # End index of context\n",
    "            end = index + window_size + 1\n",
    "            # List of context_words\n",
    "            context_words.append([words[i] for i in range(start, end) if 0 &lt;= i &lt; sentence_length and i != index])\n",
    "            # List of label_word (also is target word).\n",
    "            # print('context words {}: {}'.format(context_words, index))\n",
    "            label_word.append(word)\n",
    "            # Padding the input 0 in the left in case it does not satisfy number of context_words = 2*window_size.\n",
    "            x = sequence.pad_sequences(context_words, maxlen=context_length)\n",
    "            # print('context words padded: ', x)\n",
    "            # Convert label_word into one-hot vector corresponding with its index\n",
    "            y = np_utils.to_categorical(label_word, vocab_size)\n",
    "            yield (x, y)\n",
    "            \n",
    "            \n",
    "# Test this out for some samples\n",
    "i = 0\n",
    "window_size = 2 # context window size\n",
    "for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
    "    if 0 not in x[0]:\n",
    "        print('Context (X):', [id2word[w] for w in x[0]], '-&gt; Target (Y):', id2word[np.argwhere(y[0])[0][0]])\n",
    "    \n",
    "        if i == 10:\n",
    "            break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước 4: Xây dựng mạng nơ ron gồm 3 layers chính: \n",
    "1. Embedding layer: dùng để mã hoá đầu vào thành các one-hot véc tơ. Số lượng từ ở đầu vào chính là `2*window_size`. Sau khi mã hoá, qua quá trình training mỗi một từ vựng sẽ được biểu diễn bởi một véc tơ nhúng 100 chiều tương ứng với `embed_size`.\n",
    "2. Mean layer: Tính véc tơ trung bình của các véc tơ đầu ra ở Embedding layer. Số lượng véc tơ là `2*window_size`.\n",
    "3. Dense layer: Tính phân phối xác xuất của từ `Target` dựa vào hàm softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/phamdinhkhanh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 100)            1274600   \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12746)             1287346   \n",
      "=================================================================\n",
      "Total params: 2,561,946\n",
      "Trainable params: 2,561,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda\n",
    "embed_size = 100\n",
    "\n",
    "# build CBOW architecture\n",
    "cbow = Sequential()\n",
    "cbow.add(Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=window_size*2))\n",
    "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_size,)))\n",
    "cbow.add(Dense(vocab_size, activation='softmax'))\n",
    "cbow.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# view model summary\n",
    "print(cbow.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/phamdinhkhanh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    loss = 0.\n",
    "    i = 0\n",
    "    for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
    "        i += 1\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "        if i % 100000 == 0:\n",
    "            print('Processed {} (context, word) pairs'.format(i))\n",
    "\n",
    "    print('Epoch:', epoch, '\\tLoss:', loss)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize model structure\n",
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(cbow, show_shapes=True, show_layer_names=False, \n",
    "#                  rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-cbow.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xây dựng model skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "# generate skip-grams\n",
    "skip_grams = [skipgrams(wid, vocabulary_size=vocab_size, window_size=10) for wid in wids]\n",
    "\n",
    "# view sample skip-grams\n",
    "pairs, labels = skip_grams[0][0], skip_grams[0][1]\n",
    "for i in range(10):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d})) -&gt; {:d}\".format(\n",
    "          id2word[pairs[i][0]], pairs[i][0], \n",
    "          id2word[pairs[i][1]], pairs[i][1], \n",
    "          labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Merge\n",
    "from keras.layers.core import Dense, Reshape\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential\n",
    "\n",
    "# build skip-gram architecture\n",
    "word_model = Sequential()\n",
    "word_model.add(Embedding(vocab_size, embed_size,\n",
    "                         embeddings_initializer=\"glorot_uniform\",\n",
    "                         input_length=1))\n",
    "word_model.add(Reshape((embed_size, )))\n",
    "\n",
    "context_model = Sequential()\n",
    "context_model.add(Embedding(vocab_size, embed_size,\n",
    "                  embeddings_initializer=\"glorot_uniform\",\n",
    "                  input_length=1))\n",
    "context_model.add(Reshape((embed_size,)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([word_model, context_model], mode=\"dot\"))\n",
    "model.add(Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
    "\n",
    "# view model summary\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    loss = 0\n",
    "    for i, elem in enumerate(skip_grams):\n",
    "        pair_first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
    "        pair_second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
    "        labels = np.array(elem[1], dtype='int32')\n",
    "        X = [pair_first_elem, pair_second_elem]\n",
    "        Y = labels\n",
    "        if i % 10000 == 0:\n",
    "            print('Processed {} (skip_first, skip_second, relevance) pairs'.format(i))\n",
    "        loss += model.train_on_batch(X,Y)  \n",
    "\n",
    "    print('Epoch:', epoch, 'Loss:', loss)\n",
    "\n",
    "# visualize model structure\n",
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \n",
    "#                  rankdir='TB').create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

		</p>
		<a href="/2019/04/29/ModelWord2Vec.ipynb" sylte="color: #204081;">Xem tiếp » </a> 
		<span class="post-date" style="float: right; "><strong>29 Apr 2019</strong></span>
	  </div>
	
  
	  <div>
		<hr />
		<h2><a class="post-link" style="text-align: left; color: #204081; font-weight: bold" href="/2019/04/22/L%C3%BD_thuy%E1%BA%BFt_v%E1%BB%81_m%E1%BA%A1ng_LSTM.html">Lý thuyết về mạng LSTM part 2</a></h2>
		<br />
		<p>
		<h1 id="1-mạng-nơ-ron-truy-hồi-rnn---recurrent-neural-network">1. Mạng nơ ron truy hồi (RNN - Recurrent Neural Network)</h1>


		</p>
		<a href="/2019/04/22/L%C3%BD_thuy%E1%BA%BFt_v%E1%BB%81_m%E1%BA%A1ng_LSTM.html" sylte="color: #204081;">Xem tiếp » </a> 
		<span class="post-date" style="float: right; "><strong>22 Apr 2019</strong></span>
	  </div>
	
  
	  <div>
		<hr />
		<h2><a class="post-link" style="text-align: left; color: #204081; font-weight: bold" href="/2019/01/07/k-thu-t-feature-engineering.html">Kĩ thuật feature engineering</a></h2>
		<br />
		<p>
		<h1 id="1-giới-thiệu-về-feature-engineering">1. Giới thiệu về feature engineering</h1>


		</p>
		<a href="/2019/01/07/k-thu-t-feature-engineering.html" sylte="color: #204081;">Xem tiếp » </a> 
		<span class="post-date" style="float: right; "><strong>07 Jan 2019</strong></span>
	  </div>
	
  
</ul>

</div>

				</div>
			</div>
			<div class="col-md-2 hidden-xs hidden-sm">
				<a  href="/">
					<img width="100%" style="padding-bottom: 3mm;" src="/assets/images/logo.jpg" /> </a>
				<br>
				<nav>
					<div class="header">Khanh's site</div>
					<li><a style="text-align: left; color: #074B80"  href="https://www.facebook.com/HocExcelSQLR/">phamdinhkhanh blog</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://kaggle.com/phamdinhkhanh">phamdinhkhanh kaggle</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://rpubs.com/phamdinhkhanh">phamdinhkhanh rpub</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://github.com/phamdinhkhanh">phamdinhkhanh github</a></li>
					<br>
					<div class="header">other's site</div>
					<li><a style="text-align: left; color: #074B80"  href="https://www.facebook.com/groups/machinelearningcoban/">machine learning cơ bản facebook</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://forum.machinelearningcoban.com/">machine learning cơ bản forum</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://machinelearningmastery.com">machine learning mastery</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://viblo.asia">viblosia</a></li>
					<br>
					<div class="header">Khóa học</div>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs109/">Xác suất thống kê(Probability): CS109</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs246/">Bigdata: CS246</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://cs231n.stanford.edu/">Computer vision cơ bản: CS231N</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs224n/">Natural Language Processing: CS224N</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs224w/">Khoá phân tích mạng lưới (analysis of network): CS224W</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://web.stanford.edu/class/cs20si/">Khóa học Tensorflow: CS20SI</a></li>
				</nav>
			</div>
		</div>
	</div>
	
</body>
</html>