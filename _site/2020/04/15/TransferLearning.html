<!DOCTYPE html>
<html>

<head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#">
<meta charset="utf-8" />
<meta http-equiv='X-UA-Compatible' content='IE=edge'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>
<title>Khoa học dữ liệu</title>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
<!-- Style for main home page -->
<link rel="stylesheet" href="/assets/css/styles.css">
<link rel="stylesheet" href="/assets/css/styles_toc.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
<script data-ad-client="ca-pub-4263248182804679" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> 
<link href="https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300" rel="stylesheet">
<!-- <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet"> -->
<link href="https://fonts.googleapis.com/css?family=Roboto|Source+Sans+Pro" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Fira+Sans" rel="stylesheet">
<link rel="icon" type="image/jpg" href="assets/images/logo.jpg" sizes="32x32">
<link rel="canonical" href="https://phamdinhkhanh.github.io"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="author" content="Phạm Đình Khánh" />
<meta property="og:title" content="" />
<meta property="og:site_name" content="Khanh's blog" />
<meta property="og:url" content="https://phamdinhkhanh.github.io" />
<meta property="og:description" content="" />

<meta property="og:type" content="article" />
<meta property="article:published_time" content="" />


<meta property="article:author" content="Khanh" />
<meta property="article:section" content="" />

<link rel="alternate" type="application/atom+xml" title="Khanh's blog - Atom feed" href="/feed.xml" />
<style>
	
</style>
<!-- -- Import latext  -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
	skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
	inlineMath: [['$','$']]
  }
});
</script>

<!-- Google Analytics -->

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-89509207-1', 'auto');
// ga('send', 'pageview');
ga('send', 'pageview', {
'page': '/',
'title': ''
});
</script>


<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-KTCD8BX');</script>
<!-- End Google Tag Manager -->
</head>
<style>
body {
  padding: 0 7.5%;
}
</style>

<body>
	<div id="fb-root"></div>
	<!-- <script>(function(d, s, id) { -->
	  <!-- var js, fjs = d.getElementsByTagName(s)[0]; -->
	  <!-- if (d.getElementById(id)) return; -->
	  <!-- js = d.createElement(s); js.id = id; -->
	  <!-- js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.9"; -->
	  <!-- fjs.parentNode.insertBefore(js, fjs); -->
	<!-- }(document, 'script', 'facebook-jssdk'));</script> -->
	<br>
	<div content = "container">
		<div class="row">
			<div class="col-md-2 hidden-xs hidden-sm">
				<a  href="/">
					<img width="100%" style="padding-bottom: 3mm;" src="/assets/images/img.jpg" /> </a>
				<br>
				<nav>
					<div class="header">Latest</div>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/04/15/TransferLearning.html">Bài 33 - Phương pháp Transfer Learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/04/09/TensorflowDataset.html">Bài 32 - Kĩ thuật tensorflow Dataset</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/04/03/AWS.html">Bài 31 - Amazon Virtual Machine Deep Learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/28/deployTensorflowJS.html">Bài 30 - Xây dựng Web AI trên tensorflow js</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/23/FlaskRestAPI.html">Bài 29 - Xây dựng Flask API cho mô hình deep learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/21/faceNet.html">Bài 28 - Thực hành training Facenet</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/12/faceNetAlgorithm.html">Bài 27 - Mô hình Facenet trong face recognition</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/10/DarknetGoogleColab.html">Bài 26 - Huấn luyện YOLO darknet trên google colab</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/09/DarknetAlgorithm.html">Bài 25 - YOLO You Only Look Once</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/02/17/ImbalancedData.html">Bài 24 - Mất cân bằng dữ liệu (imbalanced dataset)</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/02/11/NARSyscom2015.html">Bài 23 - Neural Attentive Session-Based Recommendation</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/01/17/ScoreCard.html">Bài 22 - Scorecard model</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/01/06/ImagePreprocessing.html">Bài 21 - Tiền xử lý ảnh OpenCV</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/12/26/Sorfmax_Recommendation_Neural_Network.html">Bài 20 - Recommendation Neural Network</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/12/12/ARIMAmodel.html">Bài 19 - Mô hình ARIMA trong time series</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/12/02/DeepLearningLayer.html">Bài 18 - Các layers quan trọng trong deep learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/11/22/HOG.html">Bài 17 - Thuật toán HOG (Histrogram of oriented gradient)</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/11/08/RFMModel.html">Bài 16 - Model RFM phân khúc khách hàng</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/11/04/Recommendation_Compound_Part1.html">Bài 15 - collaborative và content-based filtering</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/10/22/googleHeatmap.html">Bài 14 - Biểu đồ trên Google Map</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/10/05/SSDModelObjectDetection.html">Bài 13 - Model SSD trong Object Detection</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/09/29/OverviewObjectDetection.html">Bài 12 - Các thuật toán Object Detection</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/09/16/VisualizationPython.html">Bài 11 - Visualization trong python</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/09/08/LDATopicModel.html">Bài 10 - Thuật toán LDA - Xác định Topic</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/08/25/PyTorch_Torchtext_Tutorial.html">Bài 9 - Pytorch - Buổi 3 - torchtext module NLP</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/08/19/CorrectSpellingVietnamseTonePrediction.html">Bài 7 - Pytorch - Buổi 2 - Seq2seq model correct spelling</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/08/10/PytorchTurtorial1.html">Bài 6 - Pytorch - Buổi 1 - Làm quen với pytorch</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/07/15/PySparkSQL.html">Bài 5 - Model Pipeline - SparkSQL</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/06/18/AttentionLayer.html">Bài 4 -  Attention is all you need</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/05/10/Hypothesis_Statistic.html">Apenddix 1 - Lý thuyết phân phối và kiểm định thống kê</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/04/29/ModelWord2Vec.html">Bài 3 - Mô hình Word2Vec</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/04/22/Ly_thuyet_ve_mang_LSTM.html">Bài 2 - Lý thuyết về mạng LSTM part 2</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/01/07/Ky_thuat_feature_engineering.html">Bài 1 - Kĩ thuật feature engineering</a></li>
					
				</nav>
			</div>
			<div class="col-md-8 col-xs-12" style="z-index:1">
				<nav class="navbar navbar-inverse" style="background-color: #046897">
					<div class = "container-fluid">
						<div class = "navbar-header>
							<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
								<span class="icon-bar"></span>
								<span class="icon-bar"></span>
								<span class="icon-bar"></span>
							</button>
							<a class="navbar-brand" href="/">
								<span style="color:#FFF">Khoa học dữ liệu - Khanh's blog</span>
							</a>
						</div>
						<br>
						<br>
						<div class="collapse navbar-collapse navbar-right" id="myNavbar">
							<ul class="nav navbar-nav">
								<li><a href="/home"><span style="color: #fff"> Home</span></a></li>
								<li><a href="/about"><span style="color: #fff"> About</span></a></li>
								<!-- <li><a href="/da"><span style="color: #fff">Data Analytics</span></a></li> -->
								<!-- <li><a href="/cv"><span style="color: #fff">Computer Vision</span></a></li> -->
								<!-- <li><a href="/nlp"><span style="color: #fff">NLP</span></a></li> -->
								<!-- <li><a href="/code"><span style="color: #fff">Code</span></a></li> -->
								<li><a href="/book"><span style="color: #fff">Book</span></a></li>
							</ul>
						</div>
					</div>
				</nav>
				<div class="PageNavigation">
				</div>
				<h1 itemprop="name" class="post-title"></h1>
				<div id="bootstrap-overrides">
					<div>
<h2><p class="post-link" style="text-align: left; color: #204081; font-weight: bold">Bài 33 - Phương pháp Transfer Learning</p></h2> 
<strong>15 Apr 2020 - phamdinhkhanh</strong>
</div>
<br/>
<div id="toc"></div>
<h1 id="1-giới-thiệu-chung">1. Giới thiệu chung</h1>

<p>Trong quá trình xây dựng mô hình chắc hẳn bạn đã gặp tình huống mô hình của bạn dự báo không chuẩn xác. Mặc dù đã áp dụng những kiến trúc phức tạp và được coi là state-of-art. Bạn nghi ngờ vấn đề nằm ở dữ liệu gán nhãn sai nhưng kiểm tra cho thấy vấn đề không nằm ở gán nhãn. Bạn loay hoay với câu hỏi tại sao mô hình không chuẩn xác?</p>

<p>Quá trình huấn luyện một mô hình AI trên bộ dữ liệu của bạn ngay từ đầu đôi khi dẫn tới kết quả không thực sự tốt và lãng phí tài nguyên tính toán. Trong bài viết này mình sẽ giải thích những nguyên nhân chính dẫn tới việc huấn luyện mô hình không hiệu quả. Đồng thời giới thiệu một phương pháp được áp dụng phổ biến giúp cải thiện độ chính xác và tiết kiệm chi phí thời gian huấn luyện. Phương pháp được xây dựng dựa trên ý tưởng chuyển giao tri thức đã được học từ những mô hình tốt trước đó. Đó chính là transfer learning, các bạn cùng tìm hiểu qua bài viết này nhé.</p>

<h2 id="11-nguyên-nhân-mô-hình-dự-báo-kém">1.1. Nguyên nhân mô hình dự báo kém</h2>

<p>Giả sử rằng chúng ta bỏ qua những vấn đề liên quan đến sự cố dữ liệu như gán nhãn sai, ảnh mập mờ, bị che khuất, vân vân,…. Thông thường mô hình dự báo kém là do:</p>

<ul>
  <li>
    <p><strong>Dữ liệu nhỏ không đại diện</strong>: Bộ dữ liệu của chúng ta có kích thước quá bé. Do đó mô hình được huấn luyện không học được các đặc trưng tổng quát để áp dụng vào các tác vụ phân loại. Ví dụ: Cùng là bài toán phân loại chó và mèo nhưng dữ liệu của bạn chỉ có 100 ảnh chó và ảnh mèo của Việt Nam. Số lượng này còn ít hơn số lượng các loài chó và mèo trên thế giới. Nếu áp dụng mô hình được huấn luyện trên bộ dữ liệu nhỏ sẽ dẫn tới khả năng dự báo sai trên những dữ liệu mới cao hơn.</p>
  </li>
  <li>
    <p><strong>Mô hình mất cân bằng dữ liệu</strong>: Khi mô hình mất cân bằng dữ liệu thì việc dự đoán các mẫu thuộc nhóm thiểu số khó khăn hơn. Các kĩ thuật đã được giới thiệu ở bài <a href="https://phamdinhkhanh.github.io/2020/02/17/ImbalancedData.html">Bài 24 - Mất cân bằng dữ liệu (imbalanced dataset)</a> hi vọng sẽ có ích. Trong bài này mình giới thiệu thêm kĩ thuật Data Augmentation được sử dụng cho dữ liệu ảnh.</p>
  </li>
  <li>
    <p><strong>Kiến trúc mô hình quá phức tạp</strong>: Đối với những bộ dữ liệu lớn lên tới vài triệu ảnh thì mô hình có kiến trúc phức tạp có thể mang lại độ chính xác cao. Nhưng với những bộ dữ liệu kích thước nhỏ thì mô hình phức tạp lại giảm độ chính xác. Mình cho rằng nguyên nhân chính là bởi các mô hình phức tạp thường xảy ra overfitting.</p>
  </li>
  <li>
    <p><strong>Quá trình tối ưu hóa gặp khó khăn</strong>: Có thể bạn đã thiết lập learning rate chưa tốt nên khiến mô hình huấn luyện lâu hội tụ hoặc chưa đạt tới điểm global optimal. Khi đó bạn có thể cân nhắc thay đổi phương pháp cập nhật gradient descent và thiết lập schedule learning rate. Trên <code class="highlighter-rouge">tensorflow.keras</code> chúng ta có thể thiết lập schedule learning thông qua CheckPoint như sau:</p>
  </li>
</ul>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre>import tensorflow as tf

def scheduler(epoch):
  if epoch &lt; 10:
    return 0.001
  else:
    return 0.001 * tf.math.exp(0.1 * (10 - epoch))

callback = tf.keras.callbacks.LearningRateScheduler(scheduler)
your_model.fit(data, labels, epochs=100, callbacks=[callback],
          validation_data=(val_data, val_labels))
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="12-vai-trò-của-transfer-learning">1.2. Vai trò của transfer learning</h2>

<h3 id="121-chuyển-giao-tri-thức">1.2.1. Chuyển giao tri thức</h3>

<p>Trong quá trình bùng nổ của deep learning, các tài nguyên về AI ngày càng dồi dào. Song song với quá trình phát triển đó,ngày càng có nhiều các mô hình pretrain có chất lượng tốt và độ chính xác cao. Hầu như mọi domain đều có thể tìm kiếm được các mô hình pretrain.</p>

<p>Lý thuyết về transfer learning được Lorien Pratt thực nghiệm lần đầu năm 1993 và sau đó viết lại nó dưới dạng một lý thuyết toán học vào năm 1998 đã hiện thực hóa ý tưởng về chuyển giao tri thức giữa các mô hình như giữa con người với nhau.</p>

<p>Một mô hình đã có khả năng tận dụng lại các tri thức đã huấn luyện trước đó và cải thiện lại trên tác vụ phân loại của nó.</p>

<h3 id="122-cải-thiện-accuracy-và-tiết-kiệm-chi-phí-huấn-luyện">1.2.2. Cải thiện accuracy và tiết kiệm chi phí huấn luyện</h3>

<p>Ví dụ trong bài toán phân loại chó và mèo. Nếu huấn luyện từ đầu, bạn sẽ tốn nhiều epochs huấn luyện hơn để đạt được độ chính xác cao. Tuy nhiên nếu bạn biết tận dụng lại các mô hình pretrained model thì sẽ cần ít epochs huấn luyện hơn để đạt được một độ chính xác mong đợi. Thậm chí độ chính xác có thể lớn hơn so với khi không áp dụng transfer learning.</p>

<p><img src="/assets/images/20200415_TransferLearning/pic1.jpg" class="largepic" /></p>

<p><strong>Hình 1:</strong> Sơ đồ so sánh hiệu suất mô hình trước và sau khi áp dụng transfer learning. (Nguồn: Handbook Of Research On Machine Learning Applications and Trends: Algorithms, Methods and Techniques).</p>

<p>Từ đồ thị ta có thể thấy sử dụng transfer learning sẽ mang lại 3 lợi thế chính:</p>

<ul>
  <li>Có điểm khởi đầu của accuracy tốt hơn (higher start).</li>
  <li>Accuracy có tốc độ tăng nhanh hơn (higher slope).</li>
  <li>Đường tiệm cận của độ chính xác tối ưu cao hơn (higher asymptote).</li>
</ul>

<h3 id="123-hiệu-quả-với-dữ-liệu-nhỏ">1.2.3. Hiệu quả với dữ liệu nhỏ</h3>

<p>Trong trường hợp bộ dữ liệu có kích thước quá nhỏ và khó có thể tìm kiếm và mở rộng thêm thì các mô hình được huấn luyện từ chúng sẽ khó có thể dự báo tốt. Tận dụng lại tri thức từ các mô hình pretrain với cùng tác vụ phân loại sẽ giúp các mô hình được huấn luyện dự báo tốt hơn với dữ liệu mới vì mô hình được học trên cả 2 nguồn tri thức đó là dữ liệu huấn luyện và dữ liệu mà nó đã được học trước đó.</p>

<h1 id="2-transfer-learning">2. Transfer Learning</h1>

<h2 id="21-ví-dụ-về-transfer-learning">2.1. Ví dụ về transfer learning</h2>

<p>Quá trình áp dụng tri thức đã được học từ một mô hình trước sang bài toán hiện tại được gọi là transfer learning.</p>

<p>Để hiểu rõ hơn, mình lấy ví dụ:</p>

<p>Trong bài toán dự báo dog and cat. Chúng ta có 2 nhãn cần phân loại là dog, cat và cả 2 nhãn này đều xuất hiện trong một bộ dữ liệu imagenet. Như vậy chúng ta kì vọng rằng có thể tận dụng lại các weights từ mô hình pretrain trên bộ dữ liệu imagenet để huấn luyện lại bài toán nhanh hơn, chuẩn xác hơn.</p>

<h2 id="22-kiến-trúc-mô-hình-sử-dụng-transfer-learning">2.2. Kiến trúc mô hình sử dụng transfer learning</h2>

<p>Như chúng ta đã biết các layers CNN về bản chất là một feature extractor mà mỗi một layer CNN sẽ có tác dụng trích lọc đặc trưng theo những level khác nhau.</p>

<p><img src="/assets/images/20200415_TransferLearning/pic2.jpg" class="largepic" /></p>

<p><strong>Hình 2</strong>: Các đặc trưng học được từ mạng CNN. Ở những Convolutional Layers đầu tiên, các bộ lọc phát hiện được các chi tiết chung dưới dạng các nét ngang, dọc và các cạnh của ảnh. Đây là những đặc trưng bậc thấp (low level feature) và khá chung chung. Chúng ta chưa thể nhận biết được vật thể dựa trên những đường nét này. Ở những Convolutional Layers cuối cùng là những đặc trưng bậc cao (high level feature) được tổng hợp từ đặc trưng bậc thấp. Đây là những đặc trưng tốt và có sức mạnh phân loại các classes.</p>

<p>Quá trình transfer learning sẽ tận dụng lại các đặc trưng được học từ những mô hình pretrain. Để hiểu hơn về cách thức chuyển giao, chúng ta cùng tìm hiểu về kiến trúc của mô hình sử dụng transfer learning:</p>

<ul>
  <li>phrase 1: Là một mạng Base Network có tác dụng trích lọc đặc trưng được cấu tạo từ các Convolutional 2D Layers. Base Network sẽ được trích xuất từ một phần của mô hình pretrain sau khi loại bỏ các top fully connected layers. Để dễ hình dung mình giả định model pretrained được sử dụng là VGG16, một kiến trúc khá tốt được google phát triển vào năm 2014. Điểm cải tiến của VGG16 so với các kiến trúc CNN trước đó là sử dụng nhiều Convolutional 2D Layers nối tiếp nhau. Cụ thể các layers có cấu trúc [[Conv]_n-MaxPool]_m thay vì [Conv-MaxPool]_m, với m, n là tần suất xuất hiện của các khối mạng được lặp lại bao bọc trong ngoặc vuông.</li>
</ul>

<p><img src="/assets/images/20200415_TransferLearning/pic3.jpg" class="largepic" /></p>

<p><strong>Hình 3</strong>: Kiến trúc của mạng VGG16 được sử dụng làm base network trong transfer learning.</p>

<ul>
  <li>phrase 2: Là các Fully Connected Layers giúp giảm chiều dữ liệu và tính toán phân phối xác suất ở output. Bản chất Fully Connected Layers này chính là một mạng MLP (Multiple Layer Perceptron), một kiến trúc nguyên thủy nhất của thuật toán neural network. Số lượng các units ở output chính bằng với số lượng classes của bài toán phân loại. Các hệ số của fully connected layers sẽ được khởi tạo một cách ngẫu nhiên.</li>
</ul>

<p><img src="/assets/images/20200415_TransferLearning/pic4.jpg" class="largepic" /></p>

<p><strong>Hình 4</strong>: Kiến trúc base network kết hợp với fully connected layers.</p>

<p>Quá trình khởi tạo mô hình chúng ta sẽ tận dụng lại các weight của <code class="highlighter-rouge">base_network</code>. Dữ liệu ảnh sau khi đi qua <code class="highlighter-rouge">base_network</code> sẽ tạo ra những features tốt, những feature này chính là đầu vào input $\mathbf{X}$ cho mạng MLP để dự báo $\hat{\mathbf{y}}$. Hệ số $\mathbf{W}$ và $\mathbf{b}$ được khởi tạo ngẫu nhiên. Các hệ số của base network được load lại từ pretrain model.</p>

<p>Để dễ hình dung các bước và đồng thời kiểm nghiệm hiệu quả của transfer learning, chúng ta cùng thực hành trên bộ dữ liệu dog and cat.</p>

<h1 id="3-thực-hành">3. Thực hành</h1>

<h2 id="31-dataset">3.1. Dataset</h2>

<p>Để minh họa cho phương pháp transfer learning mình sẽ huấn luyện bài toán dog and cat trên bộ dữ liệu <a href="https://github.com/ardamavi/Dog-Cat-Classifier.git">Sub Dog and Cat</a> với khoảng 1400 ảnh.</p>

<p>Bạn đọc có thể bắt đầu thực hành tại <a href="https://colab.research.google.com/drive/1EDWZxaKd6SNkAZUX1zwHXZYXPkKnFsL4">Transfer Learning</a>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre>from google.colab import drive
import os

drive.mount("/content/gdrive")
path = 'gdrive/My Drive/Colab Notebooks/TransferLearning'
os.chdir(path)
os.listdir()
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Chạy lệnh bên dưới để download dữ liệu và cd vào thư mục gốc</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>!git clone https://github.com/ardamavi/Dog-Cat-Classifier.git
%cd Dog-Cat-Classifier
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Nhớ thực hiện khảo sát dữ liệu trước khi huấn luyện model.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="rouge-code"><pre>import pandas as pd
import glob2
import matplotlib.pyplot as plt

dogs = glob2.glob('Data/Train_Data/dog/*.jpg')
dog_labels = ['dog']*len(dogs)
cats = glob2.glob('Data/Train_Data/cat/*.jpg')
cat_labels = ['cat']*len(cats)

labels = dog_labels + cat_labels
image_links = dogs + cats

data = pd.DataFrame({'labels': labels, 'image_links':image_links})
data.groupby(labels).image_links.count().plot.bar()
plt.title('Number of images in each class')
plt.show()
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/assets/images/20200415_TransferLearning/TransferLearning_13_0.png" class="largepic" /></p>

<p>Ta thấy dữ liệu giữa 2 classes là cân bằng với mỗi loại khoảng 700 ảnh. Như vậy chúng ta không xảy ra hiện tượng mất cân bằng dữ liệu. Trong trường hợp xảy ra mất cân bằng dữ liệu sẽ cần đến một số kĩ thuật xử lý đã được tổng hợp tại <a href="https://phamdinhkhanh.github.io/2020/02/17/ImbalancedData.html">Bài 24 - Mất cân bằng dữ liệu (imbalanced dataset)</a>.</p>

<h3 id="311-phân-chia-tập-trainvalidation">3.1.1. Phân chia tập train/validation</h3>

<p>Một thủ tục không thể thiếu của quá trình huấn luyện model đó là phân chia tập train/validation. Dữ liệu sẽ được huấn luyện trên tập dữ liệu train và kiểm định trên tập test. Một số qui trình phát triển model ngặt hơn còn phân chia thêm tập dev để fine tunning tham số giữa các mô hình và tập test để kiểm định mô hình trên tập dữ liệu thực tế mà người dùng sinh ra. Tuy nhiên để đơn giản hóa mình sẽ chỉ sử dụng tập train/validation.</p>

<p>Sau đó chúng ta phân chia tập train/test theo tỷ lệ 80/20. Để tỷ lệ class cân bằng giữa bộ dữ liệu train và test ta nên sử dụng hàm train_test_split của sklearn với <code class="highlighter-rouge">stratify=y</code>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre>from sklearn.model_selection import train_test_split

images_train, images_val, y_label_train, y_label_val = train_test_split(image_links, labels, stratify = labels)

print('images_train len: {}, image_test shape: {}'.format(len(images_train), len(images_val)))
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>images_train len: 1049, image_test shape: 350
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="312-data-augumentation">3.1.2. Data Augumentation</h3>

<p>Độ chính xác của một mô hình được cải thiện hay không phần lớn dựa trên 2 yếu tố chính đó là: Kiến trúc model mà bạn áp dụng và kĩ thuật data augumentation. Đặc biệt là với các bài toán có ít dữ liệu thì áp dụng data augumentation sẽ giúp gia tăng số lượng mẫu huấn luyện và cải thiện chất lượng của model.</p>

<p>Để thực hiện data augumentation trên tensorflow, chúng ta có thể config ngay trên ImageDataGenerator.</p>

<p>Nếu bạn đọc vẫn chưa quen với khái niệm ImageDataGenerator là gì, vui lòng xem lại <a href="https://phamdinhkhanh.github.io/2020/04/09/TensorflowDataset.html">Bài 32 - Kĩ thuật tensorflow Dataset</a>. Đây là kiến thức cơ bản mà bất kì một modeler nào cũng đều cần nắm vững và thực hiện khi huấn luyện mô hình.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
</pre></td><td class="rouge-code"><pre>import numpy as np
from tensorflow.keras.utils import Sequence, to_categorical
import cv2

class DataGenerator(Sequence):
    'Generates data for Keras'
    def __init__(self,
                 all_filenames, 
                 labels, 
                 batch_size, 
                 index2class,
                 input_dim,
                 n_channels,
                 n_classes=2, 
                 normalize=True,
                 zoom_range=[0.8, 1],
                 rotation=15,
                 brightness_range=[0.8, 1],
                 shuffle=True):
        '''
        all_filenames: list toàn bộ các filename
        labels: nhãn của toàn bộ các file
        batch_size: kích thước của 1 batch
        index2class: index của các class
        input_dim: (width, height) đầu vào của ảnh
        n_channels: số lượng channels của ảnh
        n_classes: số lượng các class 
        normalize: có chuẩn hóa ảnh hay không?
        zoom_range: khoảng scale zoom là một khoảng nằm trong [0, 1].
        rotation: độ xoay ảnh.
        brightness_range: Khoảng biến thiên cường độ sáng
        shuffle: có shuffle dữ liệu sau mỗi epoch hay không?
        '''
        self.all_filenames = all_filenames
        self.labels = labels
        self.batch_size = batch_size
        self.index2class = index2class
        self.input_dim = input_dim
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.shuffle = shuffle
        self.normalize = normalize
        self.zoom_range = zoom_range
        self.rotation = rotation
        self.brightness_range = brightness_range
        self.on_epoch_end()

    def __len__(self):
        '''
        return:
          Trả về số lượng batch/1 epoch
        '''
        return int(np.floor(len(self.all_filenames) / self.batch_size))

    def __getitem__(self, index):
        '''
        params:
          index: index của batch
        return:
          X, y cho batch thứ index
        '''
        # Lấy ra indexes của batch thứ index
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]

        # List all_filenames trong một batch
        all_filenames_temp = [self.all_filenames[k] for k in indexes]

        # Khởi tạo data
        X, y = self.__data_generation(all_filenames_temp)

        return X, y

    def on_epoch_end(self):
        '''
        Shuffle dữ liệu khi epochs end hoặc start.
        '''
        self.indexes = np.arange(len(self.all_filenames))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def __data_generation(self, all_filenames_temp):
        '''
        params:
          all_filenames_temp: list các filenames trong 1 batch
        return:
          Trả về giá trị cho một batch.
        '''
        X = np.empty((self.batch_size, *self.input_dim, self.n_channels))
        y = np.empty((self.batch_size), dtype=int)

        # Khởi tạo dữ liệu
        for i, fn in enumerate(all_filenames_temp):
            # Đọc file từ folder name
            img = cv2.imread(fn)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, self.input_dim)
            img_reshape = img.reshape(-1, 3)
            
            if self.normalize:
              mean = np.mean(img_reshape, axis=0)
              std = np.std(img_reshape, axis=0)
              img = (img-mean)/std

            if self.zoom_range:
              zoom_scale = 1/np.random.uniform(self.zoom_range[0], self.zoom_range[1])
              (h, w, c) = img.shape
              img = cv2.resize(img, (int(h*zoom_scale), int(w*zoom_scale)), interpolation = cv2.INTER_LINEAR)
              (h_rz, w_rz, c) = img.shape
              start_w = np.random.randint(0, w_rz-w) if (w_rz-w) &gt; 0 else 0
              start_h = np.random.randint(0, h_rz-h) if (h_rz-h) &gt; 0 else 0
              # print(start_w, start_h)
              img = img[start_h:(start_h+h), start_w:(start_w+w), :].copy()
            
            if self.rotation:
              (h, w, c) = img.shape
              angle = np.random.uniform(-self.rotation, self.rotation)
              RotMat = cv2.getRotationMatrix2D(center = (w, h), angle=angle, scale=1)
              img = cv2.warpAffine(img, RotMat, (w, h))

            if self.brightness_range:
              scale_bright = np.random.uniform(self.brightness_range[0], self.brightness_range[1])
              img = img*scale_bright
            
            label = 'dog' if 'dog' in fn else 'cat'
            label = self.index2class[label]
    
            X[i,] = img

            # Lưu class
            y[i] = label
        return X, y

dict_labels = {
    'dog': 0,
    'cat': 1
}

train_generator = DataGenerator(
    all_filenames = images_train,
    labels = y_label_train,
    batch_size = 32,
    index2class = dict_labels,
    input_dim = (224, 224),
    n_channels = 3,
    n_classes = 2,
    normalize = False,
    zoom_range = [0.5, 1],
    rotation = False,
    brightness_range=[0.8, 1],
    shuffle = True
)

val_generator = DataGenerator(
    all_filenames = images_val,
    labels = y_label_val,
    batch_size = 16,
    index2class = dict_labels,
    input_dim = (224, 224),
    n_channels = 3,
    n_classes = 2,
    normalize = False,
    zoom_range = [0.5, 1],
    rotation = False,
    brightness_range =[0.8, 1],
    shuffle = False
)
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Ở đây mình đã tự coding lại các phép biến đổi ảnh sử dụng numpy và opencv. Các bạn cũng nên tự thực hành các biết đổi này, chắc chắn kĩ năng coding và tư duy xử lý dữ liệu của các bạn sẽ cải thiện đáng kể.</p>

<p>Tùy vào mục đích biến đổi mà bạn đọc có thể thêm hoặc bớt các bước xử lý ảnh. Mình sẽ lý giải các bước xử lý chính:</p>

<p>normalize: Có thuẩn hóa mỗi một ảnh với theo phân phối chuẩn bằng cách trừ đi trung bình và chia cho phương sai toàn bộ các pixels tương ứng ở mỗi kênh.</p>

<p>zoom_range: Là một khoảng giá trị phóng đại ảnh: [lower, upper]. Giá trị phóng đại của một ảnh sẽ được sinh ngẫu nhiên nằm trong khoảng zoom_range. Giá trị phóng đại này càng nhỏ thì ảnh sẽ càng được phóng to.</p>

<p>rotation: Góc xoay ngẫu nhiên của một bức ảnh. Thông thường chỉ thiết lập từ 10-20 độ.</p>

<p>brightness_range: Khoảng điều chỉnh độ sáng cho bức ảnh. Độ sáng sẽ là một giá trị ngẫu nhiên từ [minVal, maxVal].</p>

<p>Lưu ý: Khi khởi tạo Data Generator với các mô hình sử dụng pretrained model thì chúng ta sẽ phải thực hiện các bước biến đổi dữ liệu trong data pipeline đồng nhất với pipeline được áp dụng trên pretrained model. Khi đó các features được tạo thành từ base network mới có tác dụng phân loại tốt.</p>

<p>Các phép biến đổi trên tập train và validation mình đã tham chiếu với biến đổi mà tác giả sử dụng khi thực hiện model pretrain với bộ dữ liệu imagenet từ trước.</p>

<h3 id="313-kiểm-tra-dữ-liệu-augumentation">3.1.3. Kiểm tra dữ liệu Augumentation</h3>

<p>Chúng ta không nên tin hoàn toàn vào Augumentation mà cần khảo sát lại xem những step biến đổi trên pipeline đã thay đổi dữ liệu như thế nào? Những biến đổi đó có tạo ra các mẫu phù hợp với thực tế không? Đây là một qui trình cần thiết khi huấn luyện mô hình.</p>

<p>Để kiểm tra pipeline của ImageGenerator chúng ta có thể khởi tạo vòng lặp loop qua Generator:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="rouge-code"><pre>check_aug=['Data/Train_Data/cat/cat.100.jpg']*32

check_generator = DataGenerator(
    all_filenames = check_aug,
    labels = y_label_val,
    batch_size = 20,
    index2class = dict_labels,
    input_dim = (224, 224),
    n_channels = 3,
    n_classes = 2,
    normalize = False,
    zoom_range = [0.5, 1],
    rotation = 15,
    brightness_range = [0.5, 1.5],
    shuffle = False
)
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Lấy ra một batch với kích thước là 20.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>X_batch, y_batch = check_generator.__getitem__(0)

print(X_batch.shape)
print(y_batch.shape)
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>(20, 224, 224, 3)
(20,)
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Tiếp theo ta sẽ visualize các ảnh sau augumentation</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre>import matplotlib.pyplot as plt

# Khởi tạo subplot với 4 dòng 5 cột.
fg, ax = plt.subplots(4, 5, figsize=(20, 16))
fg.suptitle('Augumentation Images')

for i in np.arange(4):
  for j in np.arange(5):
    ax[i, j].imshow(X_batch[i + j + j*i]/255.0)
    ax[i, j].set_xlabel('Image '+str(i+j+j*i))
    ax[i, j].axis('off')
plt.show()
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/assets/images/20200415_TransferLearning/TransferLearning_26_1.png" class="gigantic" /></p>

<p>Ta có thể thấy với cùng một bức ảnh nhưng đã sinh ra khá nhiều biến thể. Các thay đổi tập trung chủ yếu ở 3 khía cạnh:</p>

<ul>
  <li>Góc xoay của ảnh.</li>
  <li>Cường độ sáng của ảnh.</li>
  <li>Mức độ phóng đại của ảnh.</li>
</ul>

<h1 id="4-huấn-luyện-model">4. Huấn luyện model</h1>

<h2 id="41-khởi-tạo-model-huấn-luyện">4.1. Khởi tạo model huấn luyện</h2>

<p>Tiếp theo chúng ta sẽ huấn luyện mô hình. Việc đầu tiên cần thực hiện là khởi tạo base network cho mô hình. Trên keras đã có hầu hết các model pretrain phổ biến trên bộ dữ liệu imagenet. Lý do tác giả lựa chọn bộ dữ liệu này để huấn luyện các model pretrain là vì có tới 1000 classes khác nhau. Do đó hầu như mọi bài toán classification đều có nhãn xuất hiện trong imagenet và có thể tái sử dụng pretrain model.</p>

<p>Ta khởi tạo model như sau:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="k">from</span> <span class="n">tensorflow</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span> <span class="n">import</span> <span class="n">load_model</span><span class="p">,</span> <span class="n">Sequential</span>
<span class="k">from</span> <span class="n">tensorflow</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span> <span class="n">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="k">from</span> <span class="n">tensorflow</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">applications</span> <span class="n">import</span> <span class="n">MobileNet</span>
<span class="k">from</span> <span class="n">tensorflow</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span> <span class="n">import</span> <span class="n">Adam</span>


<span class="n">base_network</span> <span class="p">=</span> <span class="n">MobileNet</span><span class="p">(</span><span class="n">input_shape</span><span class="p">=(</span><span class="m">224</span><span class="p">,</span> <span class="m">224</span><span class="p">,</span> <span class="m">3</span><span class="p">),</span> <span class="n">include_top</span> <span class="p">=</span> <span class="nb">False</span><span class="p">,</span> <span class="n">weights</span> <span class="p">=</span> <span class="s1">'imagenet'</span><span class="p">)</span>
<span class="n">flat</span> <span class="p">=</span> <span class="n">Flatten</span><span class="p">()</span>
<span class="n">den</span> <span class="p">=</span> <span class="n">Dense</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="n">activation</span><span class="p">=</span><span class="s1">'sigmoid'</span><span class="p">)</span>

<span class="k">model</span> <span class="p">=</span> <span class="n">Sequential</span><span class="p">([</span><span class="n">base_network</span><span class="p">,</span> 
                    <span class="n">flat</span><span class="p">,</span>
                    <span class="n">den</span><span class="p">])</span>
<span class="k">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="p">=</span><span class="n">Adam</span><span class="p">(),</span> <span class="n">loss</span><span class="p">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span> <span class="p">=</span> <span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
<span class="k">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre>Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
mobilenet_1.00_224 (Model)   (None, 7, 7, 1024)        3228864   
_________________________________________________________________
flatten_6 (Flatten)          (None, 50176)             0         
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 50177     
=================================================================
Total params: 3,279,041
Trainable params: 3,257,153
Non-trainable params: 21,888
_________________________________________________________________
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Để ý kĩ bạn sẽ thấy <code class="highlighter-rouge">base network</code> là một pretrain model <code class="highlighter-rouge">VGG16</code> đã được truncate top layer thông qua tham số <code class="highlighter-rouge">include_top=False</code>. Bài toán của chúng ta có số lượng nhãn khác với imagenet nên sẽ ta gán vào base network một mạng MLP gồm các Layers Fully Connected sao cho layer cuối có số units = số lượng output classes.</p>

<p>Tiếp theo ta sẽ thực hiện quá trình warm up để huấn luyện mô hình nhanh hơn.</p>

<h2 id="42-warm-up">4.2. Warm up</h2>

<p><code class="highlighter-rouge">Warm up</code> là quá trình cần thiết để mô hình hội tụ nhanh hơn. Warm up sẽ đóng băng lại các layers CNN để cho hệ số của chúng không đổi và train lại trên các layers fully conntected cuối cùng. Mục đích của warm up là giữ nguyên được các đặc trưng tổng quát đã được học từ pretrained-model mà những đặc trưng này là tốt vì được huấn luyện trên bộ dữ liệu có kích thước lớn hơn và có độ chính xác cao hơn sao với khởi tạo hệ số ngẫu nhiên. Như vậy phrase 2 (xem hình 2) của mô hình sẽ không thay đổi input $\mathbf{X}$ và coi như chúng ta huấn luyện lại mạng MLP.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre># Frozen base_network
for layer in model.layers[:1]:
  layer.trainable = False

for layer in model.layers:
  print('Layer: {} ; Trainable: {}'.format(layer, layer.trainable))
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre>Layer: &lt;tensorflow.python.keras.engine.training.Model object at 0x7f3130e83668&gt; ; Trainable: False
Layer: &lt;tensorflow.python.keras.layers.core.Flatten object at 0x7f31333581d0&gt; ; Trainable: True
Layer: &lt;tensorflow.python.keras.layers.core.Dense object at 0x7f3130eb1898&gt; ; Trainable: True
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Huấn luyện lại model trên 1 epoch</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre>import tensorflow as tf

model.fit(train_generator,
          steps_per_epochs=len(train_generator),
          validation_data=val_generator,
          validation_steps=5,
          epochs=1)
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>32/32 [==============================] - 203s 6s/step - loss: 1.1109 - accuracy: 0.8613 - val_loss: 5.8674 - val_accuracy: 0.6125
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Bạn sẽ thấy accuracy sẽ được cải thiện rất nhanh chỉ sau epoch đầu tiên.</p>

<p>Tuy nhiên bài toán có hiện tượng overfitting khi val_accuracy thấp hơn nhiều so với train_accuracy.</p>

<p>Để giảm thiểu overfitting chúng ta sẽ thực hiện một số hiệu chỉnh đối với mô hình như:</p>

<ul>
  <li>
    <p>Mạng nơ ron có khả năng xấp xỉ được hầu hết các hàm số. Khi kiến trúc mạng càng phức tạp và bộ dữ liệu huấn luyện có kích thước nhỏ thì khả năng học được chính xác trên từng điểm dữ liệu sẽ rất tốt. Nhưng việc học này sẽ không tốt trên dữ liệu mới. Chúng ta có thể sử dụng Dropout Layer để giảm thiểu độ phức tạp trong kiến trúc của mô hình. Dropout sẽ làm nhiệm vụ cắt tỉa bớt một số kết nối Fully Connected.</p>
  </li>
  <li>
    <p>Để giảm thiểu mức độ phức tạp của hàm số chúng ta cũng có thể sử dụng các phương pháp hiệu chuẩn (regularization) bằng cách thêm vào loss function thành phần norm chuẩn của ma trận hệ số các layers.</p>
  </li>
</ul>

<script type="math/tex; mode=display">\mathcal{L}_{reg}(\mathbf{W};\mathbf{X}) = \mathcal{L}(\mathbf{W}; \mathbf{X}) + \lambda ||\mathbf{W}||_{F}^{2}</script>

<p>Trên tensorflow chúng ta có thể thêm thành phần hiệu chuẩn bằng cách khai báo trực tiếp vào tham số <code class="highlighter-rouge">kernel_regularizer</code> của keras layers:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>from tensorflow.keras import regularizers
your_model.add(Dense(64, input_dim=64,
                kernel_regularizer=regularizers.l2(0.01),
                activity_regularizer=regularizers.l2(0.01)))
</pre></td></tr></tbody></table></code></pre></div></div>

<ul>
  <li>
    <p>Một trong những nguyên nhân chủ yếu của overfitting đó là dữ liệu huấn luyện có kích thước quá bé và không tổng quát các trường hợp của ảnh. Trên thực tế bộ dữ liệu <a href="https://www.kaggle.com/c/dogs-vs-cats/data">dog and cat gốc</a> có kích thước là 25000 ảnh và lớn gấp hàng chục lần dữ liệu huấn luyện với khoảng 1000 ảnh ảnh. Tăng cường thêm dữ liệu huấn luyện cho tập train là một giải pháp có thể cân nhắc tới.</p>
  </li>
  <li>
    <p>Fine tunning lại những layers của base network để cải thiện đặc trưng (sẽ được trình bày ở phần sau).</p>
  </li>
</ul>

<h1 id="5-fine-tunning-model">5. Fine tunning model</h1>

<p>Mục đích chính của việc warm up model là để mô hình hội tụ nhanh hơn tới global optimal value.</p>

<p>Sau khi mô hình đạt ngưỡng tối ưu, sẽ rất khó để chúng ta tăng được thêm độ chính xác hơn nữa.</p>

<p>Lúc này chúng ta sẽ cần unfrozen các layers của base network và huấn luyện mô hình trên toàn bộ các layers đã được tải trọng số từ pretrain model. Quá trình này được gọi là fine-tunning.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre>for layer in model.layers[:1]:
  layer.trainable = True

for layer in model.layers:
  print('Layer: {} ; Trainable: {}'.format(layer, layer.trainable))
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre>Layer: &lt;tensorflow.python.keras.engine.training.Model object at 0x7f3130e83668&gt; ; Trainable: True
Layer: &lt;tensorflow.python.keras.layers.core.Flatten object at 0x7f31333581d0&gt; ; Trainable: True
Layer: &lt;tensorflow.python.keras.layers.core.Dense object at 0x7f3130eb1898&gt; ; Trainable: True
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>model.fit(train_generator,
          validation_data = val_generator,
          batch_size = 32,
          epochs = 5)
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>Epoch 5/5
32/32 [==============================] - 209s 7s/step - loss: 0.4418 - accuracy: 0.9180 - val_loss: 2.4136 - val_accuracy: 0.7946
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Chúng ta có thể nhận thấy rằng sau khi thực hiện fine tunning thì đồng thời accuracy trên tập train và tập validation đều tăng và đạt tới ngưỡng &gt;= 80%.</p>

<p>Như vậy fine tunning đã giải quyết được đồng thời 2 vấn đề overfitting và cải thiện accuracy của mô hình.</p>

<p>Đưa thêm hình về accuracy giữa transfer learning và mô hình gốc.</p>

<h1 id="6-kinh-nghiệm-transfer-learning">6. Kinh nghiệm transfer learning</h1>

<h2 id="61-transfer-learning-theo-kích-thước-dữ-liệu">6.1. Transfer learning theo kích thước dữ liệu</h2>

<p>Các đặc trưng học được trên ít dữ liệu sẽ có tác dụng phân loại kém hơn so với các đặc trưng được trên bộ dữ liệu kích thước lớn. Do đó:</p>

<p><img src="/assets/images/20200415_TransferLearning/pic5.jpg" class="largepic" /></p>

<p><strong>Hình 5</strong>: Chiến lược áp dụng transfer learning.</p>

<ul>
  <li>
    <p>Đối với dữ liệu nhỏ: Train lại toàn bộ các layers sẽ làm mất đi các đặc trưng đã được học từ model pretrained và dẫn tới mô hình dự báo sẽ không chính xác. Do đó chúng ta chỉ nên train lại các fully connected layers cuối.</p>
  </li>
  <li>
    <p>Đối với dữ liệu lớn và giống domain: Có thể train lại model trên toàn bộ layers. Nhưng để quá trình huấn luyện nhanh hơn thì chúng ta sẽ thực hiện bước khởi động (warm up) và sau đó mới fine tune lại mô hình.</p>
  </li>
  <li>
    <p>Đối với dữ liệu lớn và khác domain: Chúng ta nên huấn luyện lại model từ đầu vì mô hình pretrain không tạo ra được các đặc trưng tốt cho dữ liệu khác domain.</p>
  </li>
</ul>

<h2 id="62-khi-nào-thực-hiện-transfer-learning">6.2. Khi nào thực hiện transfer learning</h2>

<p>Có một số trường hợp bạn áp dụng transfer learning nhưng không thấy thực sự hiệu quả. Lý do là bởi transfer learning chỉ phù hợp với một số tình huống cụ thể như sau:</p>

<ul>
  <li>
    <p>Chỉ nên transfer learning giữa 2 mô hình có cùng domain. Mô hình pretrain A và mô hình cần huấn luyện B không có chung domain về dữ liệu thì các đặc trưng học được từ bộ feature extractor của A sẽ không thực sự hữu ích trong việc phân loại của mô hình B. Cụ thể hơn. Nếu bạn muốn xây dựng một ứng dụng âm thanh đánh thức trợ lý ảo của google bằng tiếng Việt khi nói từ :”dậy đi google”. Bạn đã có sẵn mô hình pretrain A đối với tác vụ <code class="highlighter-rouge">speech to text</code> nhưng huấn luyện trên Tiếng Anh. Như vậy bạn không nên thực hiện transfer learning trong trường hợp này. Như trong ví dụ của mình thì mô hình pretrain của imagenet đã bao gồm 2 classes dog and cat.</p>
  </li>
  <li>
    <p>Dữ liệu huấn luyện mô hình pretrain A phải lớn hơn so với mô hình B. Nếu chúng ta transfer hệ số từ một mô hình pretrain được huấn luyện trên dữ liệu có kích thước nhỏ thì các đặc trưng học được từ mô hình A sẽ không tổng quát để giúp ích phân loại dữ liệu mô hình B.</p>
  </li>
  <li>
    <p>Mô hình pretrain A phải là mô hình có phẩm chất tốt. Đây là một yêu cầu hiển nhiên vì mô hình tốt mới tạo ra được những đặc trưng tốt.</p>
  </li>
</ul>

<h1 id="7-tổng-kết">7. Tổng kết</h1>

<p>Transfer learning là một trong những phương pháp hiệu quả trong trường hợp dữ liệu có kích thước nhỏ. Ứng dụng transfer learning có thể giúp cải thiện độ chính xác của mô hình và đồng thời giảm thiểu thời gian huấn luyện.</p>

<p>Để có thể áp dụng được transfer learning hiệu quả đòi hỏi chúng ta phải có kinh nghiệm. Qua bài viết này mình đã hướng dẫn tới các bạn các tiêu chuẩn lựa chọn mô hình transfer learning. Hi vọng rằng các bạn sẽ áp dụng hiệu quả vào quá trình xây dựng và huấn luyện mô hình của mình.</p>

<h1 id="8-tài-liệu">8. Tài liệu</h1>

<ol>
  <li>
    <p><a href="https://machinelearningmastery.com/transfer-learning-for-deep-learning/">Transfer learning for deep learning - Machine learning mastery</a></p>
  </li>
  <li>
    <p><a href="https://machinelearningmastery.com/how-to-improve-performance-with-transfer-learning-for-deep-learning-neural-networks/">How to improve performance with transfer learning - Machine learning mastery</a></p>
  </li>
  <li>
    <p><a href="https://forum.machinelearningcoban.com/t/tong-hop-transfer-learning/5388">Tổng hợp transfer learning SOTA - forum machine learning cơ bản</a></p>
  </li>
  <li>
    <p><a href="https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a">A comprehensive hands on guide to transfer learning with real world applications in deep learning</a></p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=yofjFQddwHE">Transfer Learning - C3W2L07 - Andrew Ng</a></p>
  </li>
</ol>

<script data-ad-client="ca-pub-4263248182804679" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<button onclick="topFunction()" id="myBtn" title="Go to top">Top</button>

<script src="/js/toc.js"></script>
<script src="/js/btnTop.js"></script>
<script type="text/javascript">
$(document).ready(function() {
    $('#toc').toc();
});
</script>
				</div>
			</div>
			<div class="col-md-2 hidden-xs hidden-sm">
				<a  href="/">
					<img width="100%" style="padding-bottom: 3mm;" src="/assets/images/logo.jpg" /> </a>
				<br>
				<nav>
					<div class="header">Khanh's site</div>
					<li><a style="text-align: left; color: #074B80"  href="https://www.facebook.com/TowardDataScience">phamdinhkhanh blog</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://www.facebook.com/groups/3235479620010379/">phamdinhkhanh AICode forum</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://kaggle.com/phamdinhkhanh">phamdinhkhanh kaggle</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://rpubs.com/phamdinhkhanh">phamdinhkhanh rpub</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://github.com/phamdinhkhanh">phamdinhkhanh github</a></li>
					<br>
					<div class="header">other's site</div>
					<li><a style="text-align: left; color: #074B80"  href="https://www.facebook.com/groups/machinelearningcoban/">machine learning cơ bản facebook</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://forum.machinelearningcoban.com/">machine learning cơ bản forum</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://machinelearningmastery.com">machine learning mastery</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://viblo.asia">viblosia</a></li>
					<br>
					<div class="header">Khóa học</div>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs109/">Xác suất thống kê(Probability): CS109</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs246/">Bigdata: CS246</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://cs231n.stanford.edu/">Computer vision cơ bản: CS231N</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs224n/">Natural Language Processing: CS224N</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs224w/">Khoá phân tích mạng lưới (analysis of network): CS224W</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://web.stanford.edu/class/cs20si/">Khóa học Tensorflow: CS20SI</a></li>
				</nav>
			</div>
		</div>
	</div>
	
</body>
</html>
